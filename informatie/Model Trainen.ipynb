{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a665bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, FileLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f343ed-ffab-447f-b575-acba4e922a25",
   "metadata": {},
   "source": [
    "# Model Trainen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805251b-7f5d-40d8-88ed-572d9ce27166",
   "metadata": {},
   "source": [
    "### Model Keuze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02fbd1-8682-4567-b928-1405294fe1f4",
   "metadata": {},
   "source": [
    "Om te bepalen welk type model je gaat maken kijk je naar het doel van het project.\n",
    "\n",
    "   - Moet het model objecten in een afbeelding classificeren? *(De gehele afbeelding als een klasse zien)* **Classification**\n",
    "   - Moet het model objecten lokaliseren en identificeren? *(Klasse in de afbeelding vinden en de locatie daarvan)* **Detection**\n",
    "   - Moet het model elke pixel van een afbeelding classificeren in een bepaald segment? *(Is elke pixel in de afbeelding van belang?)* **Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607e501-fa19-45d1-ae03-ec85dd8dc4ce",
   "metadata": {},
   "source": [
    "Wanneer je een nieuw model wilt opbouwen is het goed om eerst naar soort gelijke projecten te kijken om te zien wat werkt. In het algemeen is de beste keuze om gebruik te maken van een pre-trained model die al kennis heeft over je klasse. Neem als voorbeeld ResNet50, een model wat getraind is op 1000 klasse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ef1f07f-e4ca-4f68-ae6e-c26509461522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='..\\Data\\imagenet-classes.txt' target='_blank'>..\\Data\\imagenet-classes.txt</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Data\\imagenet-classes.txt"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet50 classes\n",
    "FileLink('..\\\\Data\\\\imagenet-classes.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91038cf5-517d-44e5-8032-b3de61dcc4b2",
   "metadata": {},
   "source": [
    "Door zo'n voorgetraind model te nemen weet je dat de architectuur correct is voor soortgelijke opdrachten. Verder bezitten de weights al informatie over je mogelijke targets/doel klasse, dit kan het train proces een stuk sneller maken doordat het niet vanaf 0 begint. (Dit principe wordt ook transfer learning genoemd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb151b5-f9d0-48f7-afa3-be693d4ee6f8",
   "metadata": {},
   "source": [
    "Bekijk onderstaande notebook voor vragen die kunnen helpen met het maken van een keuze tussen welke pre-trained model / structuur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6224d2-9ffe-4317-a55c-41b5c9386348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Overig\\model keuze.ipynb' target='_blank'>Overig\\model keuze.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Notebooks\\Overig\\model keuze.ipynb"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('Overig\\\\model keuze.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a8d1d-0f09-4207-9074-14bbf70afbb5",
   "metadata": {},
   "source": [
    "### Hyperparameters \n",
    "Loss, optimizers en evaluatiemetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58345af3-c1f3-49c3-b4be-2ad1a7f082cd",
   "metadata": {},
   "source": [
    "Op het moment dat je de model keuze hebt gemaakt is het tijd voor de hyperparameters, dit zijn de verschillende functies / methodes die het model achter de schermen laten runnen. Dit is vaak ook het deel waar verschillende opties worden geprobeerd voor het behalen van een beter of sneller resultaat. Weet wel dat op het moment dat de data en het resultaat niet goed is dat het aanpassen van de hyperparameters dit niet toch succesvol kan maken. Zie dit meer als het bijsleutelen van het model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b2e0c-fff3-42a6-8736-87268818a0c9",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18632e3-f93b-4e6e-a9c2-8e2998c507aa",
   "metadata": {},
   "source": [
    "De criterion of vaker genoemde loss function houdt de afwijking van het model bij, specifieker de afstand tussen het voorspelde antwoord en het correcte antwoord op basis van een formule. Modellen en doeleindes verschillen zo dus ook de loss functions. Het is mogelijk onderzoek te doen naar welke loss function optimaal is voor huidige doeleindes maar raad dit af. Dit process is ook goed te doen door middel van het resultaat testen, ChatGPT vragen of na het bepalen van een optimizer een goed bijpassende loss function te kiezen.\n",
    "\n",
    "[Diepere uitleg werking loss-function](https://www.datacamp.com/tutorial/loss-function-in-machine-learning)  -  [Veel voorkomende loss-functions](https://builtin.com/machine-learning/common-loss-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9517f8-e5cb-4266-81c4-83a49e6e80d2",
   "metadata": {},
   "source": [
    "##### Standaard Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637dc1e1-05f9-4cb5-b7d4-a78a704a8ce9",
   "metadata": {},
   "source": [
    "1. **Image Classification:**\n",
    "   - **Categorical Cross-Entropy:** Wordt vaak gebruikt bij meerklasse-classificatieproblemen.\n",
    "   - **Binary Cross-Entropy:** Wordt gebruikt voor tweetalige classificatieproblemen.\n",
    "\n",
    "[Cross-Entropy](https://365datascience.com/tutorials/machine-learning-tutorials/cross-entropy-loss/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf54e3-9504-4c8d-af68-b4f6f5f250d0",
   "metadata": {},
   "source": [
    "2. **Object Detectie:**\n",
    "   - **Focal Loss:** Helpt bij het omgaan met klassenonevenwicht door moeilijkere voorbeelden te benadrukken.\n",
    "   - **Intersection over Union Loss:** Wordt soms gebruikt om de nauwkeurigheid van boksvoorstellen te verbeteren.\n",
    "   - **Smooth L1 Loss:** Wordt gebruikt in modellen zoals Faster R-CNN voor co√∂rdinatieregressie.\n",
    "   - **YOLO Loss en SSD Loss:** Specifieke combinaties van classificatie- en regressieverliezen die worden gebruikt in respectievelijk YOLO- en SSD-modellen.\n",
    "\n",
    "[YOLO Loss Explained](https://stats.stackexchange.com/questions/287486/yolo-loss-function-explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e3191-f9a5-4ba7-9f6c-5202aab943c8",
   "metadata": {},
   "source": [
    "3. **Segmentatie:**\n",
    "   - **Soft Dice Loss:** Populair in medische beeldsegmentatie, met name bij onevenwichtige klassen.\n",
    "   - **Jaccard Loss (Intersection over Union Loss):** Wordt soms gebruikt voor pixelwijzematchingscores.\n",
    "   - **Cross-Entropy Loss:** Wordt vaak gebruikt in semantische segmentatietaken voor pixelwijze classificatie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b13b8-a5ba-4fe4-9c3d-bcbc5a20a42c",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc152c8-750b-41fa-89e7-271e790aacd8",
   "metadata": {},
   "source": [
    "In Machine Learning projecten spelen optimizers in het algemeen een cruciale rol bij het trainen van modellen. De keuze voor een specifieke optimizer kan afhangen van verschillende factoren, inclusief de aard van de dataset, het model, en de gewenste balans tussen snelheid en nauwkeurigheid. Bekijk onderstaande video's voor een beter begrip over de werking van een optimizer.\n",
    "\n",
    "[3Blue 1Brown: Gradient Descent how Neural Networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w) - [Gradient Descent - 3 minutes](https://www.youtube.com/watch?v=qg4PchTECck)\n",
    "\n",
    "Hier zijn enkele standaardopties voor optimizers en overwegingen waarom je welke zou gebruiken:\n",
    "\n",
    "**Adam (Adaptive Moment Estimation):**\n",
    "\n",
    "[Adam Explained](https://builtin.com/machine-learning/adam-optimization)\n",
    "   - **Standaard Opties:** Goed gedefinieerde standaard parameters (\\(\\beta_1 = 0.9\\), \\(\\beta_2 = 0.999\\)), die meestal goede prestaties leveren zonder veel tuning.\n",
    "   - **Overwegingen:** Adam is vaak de eerste keuze als je snel resultaten wilt krijgen zonder veel tufines. Het combineert de voordelen van twee andere veelgebruikte methodes: AdaGrad en RMSProp.\n",
    "\n",
    "**Stochastic Gradient Descent (SGD):**\n",
    "\n",
    "[Stochastic Gradient Descent Explained](https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31)\n",
    "   - **Standaard Opties:** Vaak gebruikt met momentum, wat helpt om oscillaties (het heen en weer bewegen tussen twee uiterste waardes - vaak tezien in de loss) tijdens het trainen te verminderen en een snellere convergentie (het punt waarop de voorspellingen van het model niet meer verbeteren, of de loss constant wordt) te bereiken.\n",
    "   - **Overwegingen:** SGD met momentum is geschikt voor grote datasets en situaties waar je de convergentie fijn wilt afstemmen. Het vereist handmatige tuning van de leersnelheid, wat zowel een nadeel als een voordeel kan zijn.\n",
    "\n",
    "**AdaGrad:**\n",
    "   - **Standaard Opties:** Past de leersnelheid aan voor elke parameter op basis van de som van de vierkanten van alle voorgaande gradients.\n",
    "   - **Overwegingen:** Goed voor zeldzame en sprankelende kenmerken, maar kan problematisch worden als de leersnelheid te veel daalt.\n",
    "\n",
    "**RMSProp:**\n",
    "\n",
    "[RMSProp Explained](https://www.datacamp.com/tutorial/rmsprop-optimizer-tutorial)\n",
    "   - **Standaard Opties:** Houdt een bewegend gemiddelde van de vierkante gradients bij, en deelt door de wortel van deze gemiddelde waarde.\n",
    "   - **Overwegingen:** Ontwikkeld om de valkuilen van AdaGrad op te lossen, en werkt goed voor niet-stationaire doelen, wat vaak het geval is in real-world deep learning.\n",
    "\n",
    "**AdamW:**\n",
    "   - **Standaard Opties:** Een variant van Adam met decoupled weight decay. Dit voorkomt problemen die voortkomen uit de standaard L2 regularisatie in Adam.\n",
    "   - **Overwegingen:** Helpt bij de algemene generalisatie en convergentie en is vaak beter bij het trainen van transformer-gebaseerde modellen.\n",
    "\n",
    "**Nesterov Accelerated Gradient (NAG):**\n",
    "   - **Standaard Opties:** Een variatie van momentum-gebaseerde methodes die verder moet helpen om sneller te convergeren.\n",
    "   - **Overwegingen:** Het kan nuttig zijn voor zeer diepe netwerken vanwege hun abiliteit om zijn horizon van leersnelheden voor elke parameter aan te passen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91c8f6-b3dc-4e0a-a3bb-68557ccf32d4",
   "metadata": {},
   "source": [
    "##### Overwegingen bij het kiezen van een optimizer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a54da9-f76c-445f-8ebe-93e8e5122dcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- **Niet-lineaire datasets:** Opties zoals Adam helpen met het leren van complexe patronen door dynamische aanpassingen van de leersnelheid.\n",
    "- **Rekenkosten:** Simpele optimizers zoals SGD kunnen effici√´nter zijn in termen van geheugen en snelheid op heel grote datasets.\n",
    "- **Tuning-behoeften:** Sommige optimizers zoals Adam vereisen minder hyperparameter tuning, terwijl optimizers zoals SGD aanzienlijke moeite kunnen vereisen om ze goed te tunen.\n",
    "- **Generalisatie:** Weight decay en optimizerkeuzes zoals AdamW kunnen helpen om overfitting te beperken en beter te generaliseren naar testdata.\n",
    "\n",
    "Bij het kiezen van een optimizer, moet je ook overwegen wat historisch goed heeft gewerkt voor vergelijkbare taken en modellen binnen jouw specifieke domein. Het kan nuttig zijn om met verschillende optimizers te experimenteren om te zien welke het beste presteert in jouw specifieke situatie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd3e74-6062-447e-8680-4294d600ea6b",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e8eae-e727-4e37-b921-a44fd45d5300",
   "metadata": {},
   "source": [
    "Tijdens het trainen zijn er verschillende evaluatie metrics om in de gaten te houden. Bij image detection komen er nog een paar bij, deze worden in het `Image Detection` deel behandeld.\n",
    "Bij image classification zijn verschillende metrics die je kunt gebruiken om de prestaties van je model te evalueren. Hier zijn de meest voorkomende:\n",
    "\n",
    "1. **Accuracy**: Dit meet het percentage correcte voorspellingen over alle voorbeelden. Hoewel het nuttig is, kan het misleidend zijn in geval van een scheve klassenverdeling.\n",
    "\n",
    "2. **Precision**: Dit is het percentage daadwerkelijke positieve voorspellingen uit alle positieve voorspellingen. Het is vooral nuttig als de kosten van vals-positieven hoog zijn.\n",
    "\n",
    "3. **Recall (of Sensitivity)**: Dit is het percentage correcte positieve voorspellingen uit alle daadwerkelijke positieve gevallen. Het is cruciaal wanneer de kosten van gemiste positieve voorbeelden hoog zijn.\n",
    "\n",
    "4. **F1-score**: Dit is het harmonisch gemiddelde van precision en recall. Het is nuttig wanneer je een balans wilt vinden tussen precision en recall, vooral bij een ongelijke klassenverdeling.\n",
    "\n",
    "5. **Confusion Matrix**: Dit is een tabel die de prestaties van een classificatiemodel laat zien, met de werkelijke klassen tegenover de voorspelde klassen. Het geeft inzicht in correct geclassificeerde en verkeerd geclassificeerde voorspellingen.\n",
    "\n",
    "Deze metrics helpen je verschillende aspecten van je modelprestaties te begrijpen, en de keuze van welke te gebruiken hangt vaak af van de specificiteiten en eisen van je project. Zo is voor een toezicht systeem `precision` van hoger belang voor het voorkomen van false positives. Bij het herkennen van tumors is `recall` belangrijker aangezien false negatives veel schadelijker zijn dan false positives. Bepaal opbasis van wat voor jou model het handigst op welke metrics je het meest gaat letten.  In het geval je het zo simpel mogelijk voor jezelf wilt maken let dan op de `F1-score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f654648-fc3a-4c51-a697-3a8b1ddedda2",
   "metadata": {},
   "source": [
    "#### Trainingsprocedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7b938-c77f-49eb-89c1-d4d53bd89a02",
   "metadata": {},
   "source": [
    "Tijdens het train proces krijg je altijd te maken met batch size en epochs, dit zijn de hoeveelheid afbeeldingen voor het model de weights aanpast en het totaal aantal keer dat het model door de hele trainings data heen gaat. [Verdere uitleg](https://www.sabrepc.com/blog/Deep-Learning-and-AI/Epochs-Batch-Size-Iterations)\n",
    "\n",
    "Om niet zelf het aantal epochs te hoeven bepalen en zo mogelijk het proces te vroeg of laat te stoppen kan je gebruik maken van [early stopping](https://cyborgcodes.medium.com/what-is-early-stopping-in-deep-learning-eeb1e710a3cf) en/of [learning rate scheduler](https://neptune.ai/blog/how-to-choose-a-learning-rate-scheduler)\n",
    "\n",
    "__Kort om__:\n",
    "- __Batch size en epochs__: Kies de juiste batchgrootte die past bij de hoeveelheid beschikbare GPU/CPU-kracht, dit is standaard 32. Dan trainen we met voldoende epochs om een goede generalisatie te bereiken.\n",
    "- __Early stopping__: Dit is het bijhouden van de loss op de validatie set, als deze een aantal epochs niet verbeterd. We gebruiken early stopping om overfitting te voorkomen. \n",
    "- __Learning rate scheduling__: Gebruik een learning rate scheduler (bijv. reduce on plateau) om de learning rate automatisch aan te passen wanneer de prestaties stagneren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d59a18-b5ef-4c14-8544-798e33615d4d",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31653740-add1-48ed-ab29-eb85ffa1ab58",
   "metadata": {},
   "source": [
    "Tijdens het trainen zijn er verschillende metrics om in de gaten te houden. Bij image detection komen er nog een paar bij, deze worden in het `Image Detection` deel behandeld.\n",
    "Bij image classification zijn verschillende metrics die je kunt gebruiken om de prestaties van je model te evalueren. Hier zijn de meest voorkomende:\n",
    "\n",
    "1. **Accuracy**: Dit meet het percentage correcte voorspellingen over alle voorbeelden. Hoewel het nuttig is, kan het misleidend zijn in geval van een scheve klassenverdeling.\n",
    "\n",
    "2. **Precision**: Dit is het percentage daadwerkelijke positieve voorspellingen uit alle positieve voorspellingen. Het is vooral nuttig als de kosten van vals-positieven hoog zijn.\n",
    "\n",
    "3. **Recall (of Sensitivity)**: Dit is het percentage correcte positieve voorspellingen uit alle daadwerkelijke positieve gevallen. Het is cruciaal wanneer de kosten van gemiste positieve voorbeelden hoog zijn.\n",
    "\n",
    "4. **F1-score**: Dit is het harmonisch gemiddelde van precision en recall. Het is nuttig wanneer je een balans wilt vinden tussen precision en recall, vooral bij een ongelijke klassenverdeling.\n",
    "\n",
    "5. **Confusion Matrix**: Dit is een tabel die de prestaties van een classificatiemodel laat zien, met de werkelijke klassen tegenover de voorspelde klassen. Het geeft inzicht in correct geclassificeerde en verkeerd geclassificeerde voorspellingen.\n",
    "\n",
    "Deze metrics helpen je verschillende aspecten van je modelprestaties te begrijpen, en de keuze van welke te gebruiken hangt vaak af van de specificiteiten en eisen van je project. Bepaal opbasis van wat voor jou model het handigst op welke metrics je het meest gaat letten. In het geval je het zo simpel mogelijk voor jezelf wilt maken let dan op de `F1-score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a04978-1052-441c-9028-2fb91f0ab229",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38fb083",
   "metadata": {},
   "source": [
    "Dit type modellen zoals de naam al zegt probeert verschillende klasse te kunnen herkennen. Dit doet het door naar heel de afbeelding te kijken en op basis hiervan geeft het een voorspelling voor elke classen.\n",
    "\n",
    "Bekijk zo eerst een vd minimale modellen om de structuur door te krijgen voor we meer geavanceerde methodes gaan gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25910a2d-daed-4791-a5ea-f2d6b95ad75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Model Training\\ResNet50_basics.ipynb' target='_blank'>Model Training\\ResNet50_basics.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Notebooks\\Model Training\\ResNet50_basics.ipynb"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-trained ResNet50 - Zonder extra toevoegingen\n",
    "FileLink('Model Training\\\\ResNet50_basics.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc04d9",
   "metadata": {},
   "source": [
    "In onderstaande notebook werken we ook een ResNet50 model uit. Maar in dit geval hebben we toevoegingen gedaan om overfitting tegen te gaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18131157-50e1-4d0c-b822-4774b064f78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Model Training\\ResNet50.ipynb' target='_blank'>Model Training\\ResNet50.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Notebooks\\Model Training\\ResNet50.ipynb"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-trained ResNet50 - Onderbouw keuzes \n",
    "FileLink('Model Training\\\\ResNet50.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9f098-0e6d-490a-8231-ba1325975eb8",
   "metadata": {},
   "source": [
    "### Image Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef1e5e-c43e-4190-afe8-e406469afc6f",
   "metadata": {},
   "source": [
    "Hierbij wordt een object in de afbeelding gevonden ipv dat de hele afbeelding als het object of de klasse wordt gezien. Dit heeft verschillende effecten als een andere structuur voor de data en het model, de benodigde hoeveelheid data, trainingstijd maar vooral ook het resultaat van het model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ea40aad-9ed1-4a04-b337-b30ab41c18b2",
   "metadata": {},
   "source": [
    "### Algemene Image Detection Uitleg\n",
    "- Hoe Image Detection werkt\n",
    "- Bounding Boxes\n",
    "- Exclusieve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96d48f16-cb34-421e-bfdc-29fe00af2ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Model Training\\Training YOLO model.ipynb' target='_blank'>Model Training\\Training YOLO model.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Notebooks\\Model Training\\Training YOLO model.ipynb"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('Model Training\\\\Training YOLO model.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

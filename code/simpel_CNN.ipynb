{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f9827f-5411-4eb2-9bac-f2b8e9f535a4",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "Deze versie is gemaakt op 11-12 na het maken van de grotere set eigen afbeeldingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e03054-4940-4d92-bd15-efcb3bc4c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1e862d-8775-4a1b-b151-22cee4443d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs =50\n",
    "learning_rate = 0.00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748515ac-c582-4327-8d2f-caaf97495949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Lambda(lambda x: x / 255.0)  # Normalize by dividing by 255\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2043c8fe-6077-47ad-b4f5-25345700af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets CROPPED NO PADDING\n",
    "train_dataset = datasets.ImageFolder('data/cropped_no_padding/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.ImageFolder('data/cropped_no_padding/test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48670ca-0ef6-46e4-bea2-8abc2027177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets CROPPED NO PADDING\n",
    "train_dataset = datasets.ImageFolder('data/cropped_no_padding/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.ImageFolder('data/cropped_no_padding/test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0c8e06-14e3-426f-b370-89157c02f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of outputs for the first fully connected layer\n",
    "final_feature_map_size = 224 // (2 * 2)  # After two 2x2 max pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52cc4c82-f3c0-4ae4-9412-fdd557a49926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(32 * final_feature_map_size * final_feature_map_size, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)  # Flatten\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90553005-1a5c-4541-9e7a-dcdd4fde5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define the loss function and the optimizer\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = CNN(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8959347-bd9e-41ea-a243-33fcbc4b2b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.1173\n",
      "Epoch [2/50], Loss: 0.1141\n",
      "Epoch [3/50], Loss: 0.0442\n",
      "Epoch [4/50], Loss: 0.0389\n",
      "Epoch [5/50], Loss: 0.0165\n",
      "Epoch [6/50], Loss: 0.0228\n",
      "Epoch [7/50], Loss: 0.0055\n",
      "Epoch [8/50], Loss: 0.0102\n",
      "Epoch [9/50], Loss: 0.0255\n",
      "Epoch [10/50], Loss: 0.0104\n",
      "Epoch [11/50], Loss: 0.0103\n",
      "Epoch [12/50], Loss: 0.0054\n",
      "Epoch [13/50], Loss: 0.0238\n",
      "Epoch [14/50], Loss: 0.0149\n",
      "Epoch [15/50], Loss: 0.0045\n",
      "Epoch [16/50], Loss: 0.0076\n",
      "Epoch [17/50], Loss: 0.0023\n",
      "Epoch [18/50], Loss: 0.0036\n",
      "Epoch [19/50], Loss: 0.0019\n",
      "Epoch [20/50], Loss: 0.0019\n",
      "Epoch [21/50], Loss: 0.0019\n",
      "Epoch [22/50], Loss: 0.0004\n",
      "Epoch [23/50], Loss: 0.0010\n",
      "Epoch [24/50], Loss: 0.0020\n",
      "Epoch [25/50], Loss: 0.0161\n",
      "Epoch [26/50], Loss: 0.0014\n",
      "Epoch [27/50], Loss: 0.0021\n",
      "Epoch [28/50], Loss: 0.0017\n",
      "Epoch [29/50], Loss: 0.0021\n",
      "Epoch [30/50], Loss: 0.0009\n",
      "Epoch [31/50], Loss: 0.0006\n",
      "Epoch [32/50], Loss: 0.0006\n",
      "Epoch [33/50], Loss: 0.0005\n",
      "Epoch [34/50], Loss: 0.0005\n",
      "Epoch [35/50], Loss: 0.0005\n",
      "Epoch [36/50], Loss: 0.0010\n",
      "Epoch [37/50], Loss: 0.0004\n",
      "Epoch [38/50], Loss: 0.0003\n",
      "Epoch [39/50], Loss: 0.0002\n",
      "Epoch [40/50], Loss: 0.0004\n",
      "Epoch [41/50], Loss: 0.0007\n",
      "Epoch [42/50], Loss: 0.0035\n",
      "Epoch [43/50], Loss: 0.0017\n",
      "Epoch [44/50], Loss: 0.0008\n",
      "Epoch [45/50], Loss: 0.0009\n",
      "Epoch [46/50], Loss: 0.0004\n",
      "Epoch [47/50], Loss: 0.0008\n",
      "Epoch [48/50], Loss: 0.0002\n",
      "Epoch [49/50], Loss: 0.0002\n",
      "Epoch [50/50], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f329b2e-deba-4301-8cf0-44d89782b983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 99.55%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45b1eee-166f-422e-98e7-37c1c570492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aantal klassen in je model (bijvoorbeeld 75 klassen)\n",
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae20a3a5-9eb0-4603-ac86-ae017e692712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gebruik een dummy input die overeenkomt met de input van je model\n",
    "dummy_input = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344d4446-d998-4c15-88d0-2033f6f97304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporteer het model naar ONNX-formaat\n",
    "torch.onnx.export(model, dummy_input, 'cropped_cnn.onnx', input_names=['input'], output_names=['output'], opset_version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d0157-6b3b-4b86-a8b0-7a27993b5bd3",
   "metadata": {},
   "source": [
    "## Resultaten bekijken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bcb3126-8ad3-44a2-af03-6844458eeb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_onnx_model(model_path):\n",
    "    \"\"\"\n",
    "    Load an ONNX model and return the inference session.\n",
    "    \n",
    "    :param model_path: Path to the ONNX model file.\n",
    "    :return: ONNX runtime inference session.\n",
    "    \"\"\"\n",
    "    return ort.InferenceSession(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdae6d04-74a5-4346-8464-d5116199993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_session = load_onnx_model(\"D:/Studie/Stage/Demo/model_structuur_vergelijken/Models/cropped image classification/cropped_cnn.onnx\")\n",
    "input_name = cropped_session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498bbef4-41ed-406c-851d-d66a5defe359",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder('data/imagenet_format_dataset/val', transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c00912f-cad4-413e-95ca-234bd895b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder('data/cropped_no_padding/val', transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc6acba8-34ad-4853-a3b2-853477305ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct = 0\n",
    "total_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2984fe9e-b19a-4d98-9d6c-a974509356cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        # Schakel PyTorch tensoren om naar numpy arrays\n",
    "        images_np = images.numpy()\n",
    "\n",
    "        # Doen voorspellingen\n",
    "        outputs = cropped_session.run(None, {input_name: images_np})\n",
    "\n",
    "        # Hier wordt verondersteld dat de uitvoer de logit/probabiliteitswaarden zijn\n",
    "        predictions = np.argmax(outputs[0], axis=1)\n",
    "        # print(predictions)\n",
    "\n",
    "        # Bereken het aantal correcte voorspellingen\n",
    "        total_correct += (predictions == labels.numpy()).sum()\n",
    "        total_samples += labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bcaa890-2877-4d6b-a607-098b2b25072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nauwkeurigheid: 98.83%\n"
     ]
    }
   ],
   "source": [
    "# Print de nauwkeurigheid van het model\n",
    "accuracy = total_correct / total_samples\n",
    "print(f'Nauwkeurigheid: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d3678-a7df-442f-85af-34460fafa112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

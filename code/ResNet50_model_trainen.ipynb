{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3353fa-4b24-402d-be29-609f75e8dba2",
   "metadata": {},
   "source": [
    "# ResNet50 Trainen\n",
    "In deze notebook gaan we een pre-trained ResNet50 model door trainen met onze eigen dataset en klassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3a750f-74dd-4db7-bec6-2278eaad9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import FileLink, FileLinks\n",
    "\n",
    "from collections import defaultdict\n",
    "from fractions import Fraction\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from transformer import ResizeWithRandomRotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18bec4-b5f1-4aae-a166-d863d13ebf4e",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87944fc-5e2b-4e82-a859-9adc9caf2777",
   "metadata": {},
   "source": [
    "Deze notebook richt zich alleen op het uitvoeren van het train proces, hieronder vind je code op een blik te kunnen doen op de waardes van de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb76c54d-4f1a-4517-b994-1570f37016bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Data Understanding.ipynb' target='_blank'>Data Understanding.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Computer-Vision-Showcase-SUPERP\\code\\Data Understanding.ipynb"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('Data Understanding.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73236e1c-7867-4ec6-9fb9-0acc4069dac6",
   "metadata": {},
   "source": [
    "#### Image Processing\n",
    "De aanpassingen die we hier op de dataset gaan doen staan in onderstaande notebook. Dit is ook waar we het gemiddelde en de standaardafwijking berekenen die we later bij normalize gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9bf5a6-4e89-43d1-b19d-f68d708c4b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Image Processing.ipynb' target='_blank'>Image Processing.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Computer-Vision-Showcase-SUPERP\\code\\Image Processing.ipynb"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('Image Processing.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035d55d-5369-43a9-b93b-6073aa436263",
   "metadata": {},
   "source": [
    "### Model Trainen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d527fa9-ee08-4a27-8468-80656c188fc0",
   "metadata": {},
   "source": [
    "In deze notebook gaan we dieper in op verschillende mogelijkheden tijdens het door trainen van een pre-trained image classification model. [Waarom pre-trained en waar kan je pre-trained models vinden](https://www.reduct.store/blog/pre-trained-models-computer-vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ddf8b-f3d8-4656-af92-c7fff04b3688",
   "metadata": {},
   "source": [
    "#### Data laden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f74d8a-d055-4d0f-b1ee-cd92841bb7ac",
   "metadata": {},
   "source": [
    "__Let op:__ Voor je het een model kan trainen moet je eerst een eigen dataset toevoegen of maak gebruik van de `selfmade_data`. *(voor een snelle test of het werkt is deze dataset alleen iets te groot)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7966e11a-5cdf-4157-8e25-d977e08bef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path naar data folder\n",
    "data_dir = '..//images//selfmade_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "300ac267-918e-426f-85df-6a03abbd81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aantal klasse in de dataset\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cad3b48-e5ac-4bfa-9dee-c928ba8b0116",
   "metadata": {},
   "source": [
    "##### Standaard instellingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb68857f-a348-4f77-a477-d7b19c4dfdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Instellingen\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345e1db-08f2-4322-94a6-0ef80895e5a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Error handeling\n",
    "Tijdens het trainprocess is het mogelijk onverwachte problemen tegen te komen zoals het verdwijnen van afbeeldingen uit je dataset.\n",
    "In onderstaande geval werden afbeeldingen tijdens het trainen van het model corrupt geraakt waardoor het train process een foutmelding gaf.\n",
    "\n",
    "`UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='E:\\\\Studie\\\\Stage\\\\combined\\\\Banaan\\\\56.jpeg'>`\n",
    "\n",
    "*(In dit geval raakte de scraped images corrupt)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929b1280-40c2-496c-bcb9-eb9b58cf7a13",
   "metadata": {},
   "source": [
    "### Check Corrupted\n",
    "Onderstaande code checkt of afbeeldingen voor het train process al corrupt zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59593d5e-94e5-47ca-b259-7154bb40da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = data_dir\n",
    "\n",
    "# Loop door alle directories en subdirectories\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(subdir, filename)\n",
    "        try:\n",
    "            with Image.open(filepath) as img:\n",
    "                img.verify()  # Verifieert de integriteit zonder te laden\n",
    "        except (IOError, SyntaxError, Image.UnidentifiedImageError) as e:\n",
    "            print(f'Probleem met bestand: {filepath} - {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed86f92-c9c7-4e6f-884d-df28d21cc140",
   "metadata": {},
   "source": [
    "Van te voren zijn afbeeldingen nog niet corrupt maar dit kan wel tijdens het proces gebeuren.\n",
    "\n",
    "Gelukkig kunnen we deze code gebruiken om de dataloader aan te passen. We neemen de ImageFolder van Pytorch en 'veranderen' de `__getitem__()`. Elke keer als een batch van de afbeeldingen wordt ingeladen wordt elke afbeelding gecheckt tot de afbeelding is ingeladen of een foutmelding opleverd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e600b8e4-3b10-48cd-b28f-3bb568a40037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        while True:\n",
    "            try:\n",
    "                return super(SafeImageFolder, self).__getitem__(index)\n",
    "            except (IOError, OSError, Image.UnidentifiedImageError):\n",
    "                print(f'Fout bij het laden van bestand bij index {index}, overslaan.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1417e6-0a40-46d3-a7a6-86661ec3c2f3",
   "metadata": {},
   "source": [
    "#### SafeImageFolder: Een robuuste DataLoader - Extra Informatie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e146744-e652-4447-9164-e9cbca7a1a11",
   "metadata": {},
   "source": [
    "De `SafeImageFolder` klasse is een aangepaste versie van de PyTorch `ImageFolder`, ontworpen om robuuster om te gaan met het laden van afbeeldingsdata. Het bevat een verbeterde foutafhandeling die problemen zoals corrupte bestanden tijdens het inladen van afbeeldingen op een veilige manier afvangt.\n",
    "##### Kernfunctionaliteit:\n",
    "- **Overerving van ImageFolder**: Neemt alle basisfunctionaliteit van `ImageFolder` over, waardoor het eenvoudig te gebruiken is met bestaande PyTorch data pipelines.\n",
    "- **Veilig Laden met Foutafhandeling**:\n",
    "  - De `__getitem__` methode herhaalt het laden van een afbeelding tot het succesvol is of een onherstelbare fout optreedt.\n",
    "  - Vangt specifieke fouten op zoals `IOError`, `OSError` en `Image.UnidentifiedImageError`, en slaat beschadigde of onleesbare bestanden over met een melding.\n",
    "##### Praktische Voordelen:\n",
    "- **Robuuste Data Loading**: Fouten worden opgevangen zowel bij het initialiseren van de dataset als gedurende het trainen, valideren, of testen. Dit betekent dat als een bestand plotseling corrupt raakt, het trainingsproces niet crasht.\n",
    "- **Betrouwbaarheid**: Verhoogt de betrouwbaarheid van het trainingsproces, vooral nuttig bij het werken met grote datasets of datasets van wisselende kwaliteit.\n",
    "Gebruik `SafeImageFolder` om ervoor te zorgen dat je modeltraining zonder onderbreking verloopt, zelfs wanneer je te maken hebt met onbetrouwbare data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50cf8b-a135-4f11-90c5-fb39bc0f68b0",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Om overfitting te voorkomen kan je ook gebruik maken van Early Stopping. Early Stopping is zoals de naam al zegt een class die het train process tussentijds stop kan zetten.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3e5a7c2-1e50-4964-88f9-88f6e770f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0, save_path=None):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.save_path = save_path  # Pad om het beste model op te slaan\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.save_path:\n",
    "                torch.save(model.state_dict(), self.save_path)  # Model opslaan\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        return self.counter >= self.patience #<--- Ga dit nog nader checken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea87c6-0abe-4f07-9b14-4481315cb85d",
   "metadata": {},
   "source": [
    "##### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd4502-c019-4407-8a0c-9b5ad3911e8c",
   "metadata": {},
   "source": [
    "Overfitting is wanneer een model te ver doorgetraind is op een dataset waardoor het resultaat op nieuwe data slechter wordt.\n",
    "Overfitting is een veelvoorkomend probleem in machine learning waarbij een model te goed presteert op de trainingsdata maar slecht generaliseert naar nieuwe, ongeziene data. \n",
    "\n",
    "Hier zijn enkele kenmerkende signalen van overfitting:\n",
    "\n",
    "- **Hoge Training Prestaties maar Lage Validatie/Test Prestaties**:\n",
    "Het model behaalt lage foutpercentages of hoge nauwkeurigheid op de trainingsdataset, maar laat hoge foutpercentages of lage nauwkeurigheid zien op de validatie- of testdataset.\n",
    "- **Toenemende Kloof tussen Training en Validatie Fouten**:\n",
    "Tijdens het trainen daalt de fout (bijvoorbeeld verlies) op de trainingsset constant, terwijl de validatie- of testfout op een gegeven moment begint te stijgen of stabiliseert en dan verslechtert.\n",
    "- **Lange Trainingstijd zonder Algemene Verbeteringen**:\n",
    "Het model blijft beter presteren op de trainingsset bij langere trainingstijd, maar prestaties op de validatie- of testset blijven stagneren of worden slechter.\n",
    "- **Complex Model met Vergeleken met Data**:\n",
    "Een model met een hoge capaciteit (bijvoorbeeld diep netwerk met veel parameters) toegepast op een relatief kleine dataset kan overmatig de specifieke details van de trainingsdata leren.\n",
    "- **Visueel Indicaties**:\n",
    "Bij het plotten van de verliescurves voor training en validatie, een uiteenlopende visualisatie waarin de validatie curve omhoog gaat terwijl de trainings curve blijft dalen, duidt vaak op overfitting.\n",
    "- **Ruis Leren**:\n",
    "Het model begint specifieke ruis of uitzonderlijke patronen in de trainingsset te leren, die niet representatief zijn voor de bredere dataset.\n",
    "\n",
    "Het herkennen van overfitting is onderdeel van het reguliere proces van het ontwikkelen van machine-learning-modellen. Technieken zoals regularisatie, vroegtijdig stoppen, cross-validatie, en data-augmentatie kunnen helpen overfitting te verminderen en de generaliserende kracht van je model te verbeteren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e1483-f9f0-4834-bfdd-3f9ce86f6870",
   "metadata": {},
   "source": [
    "### Inladen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ffe744c-90ca-4ecc-b7dd-797b3ff45c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet standaard\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6b806bf-f6ad-47dc-b372-b725411a1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.5146, 0.5071, 0.5064]\n",
    "std = [0.1779, 0.1722, 0.1627]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d9cac42-b0ea-4f62-954f-efc793ae1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatransformaties\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    ResizeWithRandomRotation(img_size, 25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff7e67eb-b718-475a-a73b-c546eb6c806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laad de dataset\n",
    "# full_dataset = datasets.ImageFolder(root=data_dir, transform=transform) <-- de standaard image folder call\n",
    "full_dataset = SafeImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Verdeel de dataset in training-, validatie- en testdata\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.15 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b615c-3579-4379-91ef-3e052825a154",
   "metadata": {},
   "source": [
    "#### Model Inladen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55641d55-6771-4240-bc5b-1ca0474a56af",
   "metadata": {},
   "source": [
    "We geven hier aan dat we het ResNet50 model willen gebruiken met de standaard weights van het model, in het geval je een eigen model zou willen trainen moet je deze structuur eerst zelf opzetten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80c216e0-e46b-4567-9d55-10403e5aa9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laad het ResNet-50 model\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59d88df0-d4b5-4d2d-aedb-1972bfea1995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='simpel_CNN.ipynb' target='_blank'>simpel_CNN.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Computer-Vision-Showcase-SUPERP\\code\\simpel_CNN.ipynb"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eigen model structuur\n",
    "FileLink('simpel_CNN.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa2e1f-2e43-4b35-b530-305f9b96240a",
   "metadata": {},
   "source": [
    "##### Change Input Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb29a32-017e-4dc5-9a16-575edd32f0ac",
   "metadata": {},
   "source": [
    "Op het moment dat je de resolutie van de input 224x224 wilt houden hoeft de `input_tensor` niet worden aangepast. In andere gevallen is dit hoe je dat toepast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b14d9fdf-3217-47c0-b90f-b08c992eede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 3, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc9b6eab-b8c8-4b29-911d-3bca66c341c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ba45557-e0e8-4eb3-b5ff-f662e0864b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)  # Controleer of de uitvoer overeenkomt met het verwachte aantal klassen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf492e5b-fcf3-4a7c-b462-297977029dc6",
   "metadata": {},
   "source": [
    "##### Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87061cc2-8f24-42c8-8cb2-7b026e851265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verplaats het model naar GPU als dat beschikbaar is\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a877ef2-5831-4801-85e6-139cdb3819b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddeed44-26a8-4bfa-ac0c-6ec644c7db4d",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042a91b-3cbe-4c31-9a2d-3b948067332f",
   "metadata": {},
   "source": [
    "#### Early Stopping Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f5dbd-f85c-41a4-a9ed-c42b1dc3f4f1",
   "metadata": {},
   "source": [
    "`min_delta` is de minimale hoeveelheid dat de loss moet verbeteren ten opzichte van de vorige epoch. `patience` is het aantal epochs dat het wachten op deze verbetering maximaal gaat duren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d9b2ed5-a984-4251-a630-666ee4b8e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standaard instellingen\n",
    "patience = 5\n",
    "min_delta = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "730ff7fe-7cc2-4dc3-9461-a3cfdc9c68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiseren van EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=patience, min_delta=min_delta, save_path=\"ResNet50_best_val_score.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a956678b-4b0b-4f4e-8205-ac4ea6c6f5a0",
   "metadata": {},
   "source": [
    "#### Criteria en Loss\n",
    "In het trainen van computervisie-modellen, zoals CNN's, is het essentieel om een geschikte verliesfunctie (loss function) te kiezen, omdat deze fungeert als een maatstaf voor hoe goed het model presteert. \n",
    "- **Criterion**: Dit verwijst naar de verliesfunctie die gekozen is voor het model. In de context van classificatiemodellen voor computervisie, vooral wanneer er meerdere klassen zijn, is `nn.CrossEntropyLoss` een veelgebruikte keuze. Deze verliesfunctie combineert `nn.LogSoftmax` en `nn.NLLLoss` in één enkele stap en is daarom efficiënter en nauwkeuriger voor het berekenen van de verschillen tussen de voorspelde klassen en de werkelijke klassen. Het stuurt het model aan om het logaritmische verschil tussen voorspellingen en waarheidslabel te minimaliseren.\n",
    "#### Keuzes Onderbouwd voor Optimizer\n",
    "1. **Adam Optimizer**:\n",
    "   - Voordelen: Adam (Adaptive Moment Estimation) past leerrates aan voor elke parameter individueel en automatiseert veel van de gewenste eigenschappen van de reguliere Stochastic Gradient Descent (SGD). Het vereist minder fijnafstelling en werkt goed voor een snel convergeren van modellen.\n",
    "   - Nadelen: Het kan minder goed generaliseren in sommige scenario's, omdat het de neiging heeft om zich sterk aan te passen aan de trainingsdata (potentieel meer vatbaar voor overfitting).\n",
    "2. **SGD met Momentum en Weight Decay**:\n",
    "   - **SGD**: Stochastic Gradient Descent is klassiek en krachtig, maar kan traag convergeren zonder extra technieken.\n",
    "   - **Momentum**: Dit helpt om de convergentiesnelheid te verhogen door ervoor te zorgen dat het model zijn voortgang in een bepaalde richting voortzet, waardoor het leerproces stabieler wordt.\n",
    "   - **Weight Decay**: Dit voegt L2 regularisatie toe, wat helpt de overfitting te beperken door te straffen voor te grote gewichten.\n",
    "   - Voordelen: Deze configuratie kan leiden tot betere generalisatieprestaties en is vaak de voorkeur bij grotere datasets of wanneer zo hoog mogelijke nauwkeurigheid gewenst is. Het is wel gevoeliger voor hyperparameterinstellingen (zoals leersnelheid) dan Adam.\n",
    "\n",
    "De keuze voor de SGD optimizer met momentum en weight decay suggereert een voorkeur voor verfijning en optimalisatie, waarbij het risico van overfitting wordt beperkt en de model algemene prestatie verbeterd. Door het gewicht van parameters onder controle te houden en de richting van de update te stabiliseren, leert het model vaak robuuster en effectiever voor het geven van generaliserende resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8869b6d6-58d8-4354-b3f4-b6b2fa5e0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss en optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate) OLD\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56564ddb-5e69-4e9b-8a87-7394f49dd719",
   "metadata": {},
   "source": [
    "#### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "643e31dd-92f5-40f0-8b30-1968052e6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiseer de scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981e576a-ddce-45f6-8890-4ffe2c4cd253",
   "metadata": {},
   "source": [
    "##### Verklaring hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8eb04f-c352-4d43-a473-88d9b6e5b3db",
   "metadata": {},
   "source": [
    "`Momentum=0.9` dit maakt het verschil tussen Stochastic Gradient Descent (SGD) en Stochastic Gradient Descent with Momentum (SGDM)\n",
    "Je zou hier kunnen testen tussen 0.8 en 0.99 maar historisch gezien is 0.9 bewezen effectief bij veel beeldherkenningsproblemen.\n",
    "Aangezien het train proces al erg lang duurt gaan we dit niet testen.\n",
    "`weight_decay=0.0001` is om overfitting te voorkomen, dit is een gebruikelijke waarde wat effect zou hebben maar niet te heftig is en andere problemen kan veroorzaken. \n",
    "`step_size=7` betekent dat om de 7 epochs de learning rate wordt verlaagd.\n",
    "`gamma=0.1` is het percentage waarmee de learning rate wordt verlaagd, in dit geval zou dus elke 7 steps de learningrate met 10% worden verminderd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75862e6f-1123-4b16-a3ce-ec1e58024be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Luuk\\anaconda3\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49, Loss: 1.2958, Tijd epoch: 191.26768112182617 seconden\")\n",
      "Validation Loss: 0.4058\n",
      "Epoch 1/49, Loss: 0.1861, Tijd epoch: 188.1691288948059 seconden\")\n",
      "Validation Loss: 0.0608\n",
      "Epoch 2/49, Loss: 0.0676, Tijd epoch: 191.78909420967102 seconden\")\n",
      "Validation Loss: 0.0338\n",
      "Epoch 3/49, Loss: 0.0401, Tijd epoch: 191.11213541030884 seconden\")\n",
      "Validation Loss: 0.0251\n",
      "Epoch 4/49, Loss: 0.0260, Tijd epoch: 191.41813325881958 seconden\")\n",
      "Validation Loss: 0.0258\n",
      "Epoch 5/49, Loss: 0.0241, Tijd epoch: 190.72707557678223 seconden\")\n",
      "Validation Loss: 0.0167\n",
      "Epoch 6/49, Loss: 0.0224, Tijd epoch: 188.31207513809204 seconden\")\n",
      "Validation Loss: 0.0112\n",
      "Epoch 7/49, Loss: 0.0139, Tijd epoch: 189.96711468696594 seconden\")\n",
      "Validation Loss: 0.0139\n",
      "Epoch 8/49, Loss: 0.0179, Tijd epoch: 190.42907571792603 seconden\")\n",
      "Validation Loss: 0.0159\n",
      "Epoch 9/49, Loss: 0.0137, Tijd epoch: 189.8340663909912 seconden\")\n",
      "Validation Loss: 0.0152\n",
      "Epoch 10/49, Loss: 0.0134, Tijd epoch: 189.241055727005 seconden\")\n",
      "Validation Loss: 0.0126\n",
      "Early stopping\n",
      "Training compleet\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}, Tijd epoch: {end - start} seconden\")')\n",
    "\n",
    "    # Validatie\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Scheduler stap na elke epoch  \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Controleer voor early stopping\n",
    "    # if early_stopping(val_loss):\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "print('Training compleet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e85671-5132-4d72-8f42-74b572312f4f",
   "metadata": {},
   "source": [
    "### Model Opslaan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc1966-58e5-4fd1-bfd1-57a124249a8d",
   "metadata": {},
   "source": [
    "Nadat het model is getraind is het handig om het model op te slaan. Hierbij kunnen we weer gebruik maken van torch om de gewichten van het model te downloaden. Het is ook mogelijk zelf gelijk het model om te zetten naar het de manier hoe je het wilt gebruiken maar vooral voor relatieve beginners raad ik aan dit stap voor stap te doen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1a6676d-62e4-4330-91ec-9d9c170e20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opslaan van het model\n",
    "torch.save(model.state_dict(), 'default_name.pth') # Vergeet niet te hernoemen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533da96-9a3a-46fe-b180-f78fd8f499cf",
   "metadata": {},
   "source": [
    "    Geef het .pth bestand een logische naam waar het model aan te herkennen is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15dd54-0c7b-436d-87d6-81d388a25f28",
   "metadata": {},
   "source": [
    "# Model Gebruiken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b7aea9-eb56-4565-a6fa-81cec46bbe42",
   "metadata": {},
   "source": [
    "Normaal gesproken hoef je het model niet opnieuw in te laden na het trainen van het model. Echter staat nu het gebruiken van het model in een andere notebook dus hebben we het .pth bestand nodig om niet opnieuw het train proces te hoeven draaien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51b36eae-81b5-4fe9-b26f-9fc3a5fc504d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='ResNet50_model_gebruiken.ipynb' target='_blank'>ResNet50_model_gebruiken.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Computer-Vision-Showcase-SUPERP\\code\\ResNet50_model_gebruiken.ipynb"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('ResNet50_model_gebruiken.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

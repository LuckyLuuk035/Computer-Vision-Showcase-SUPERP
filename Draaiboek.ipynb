{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ea0252",
   "metadata": {},
   "source": [
    "# Draaiboek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908afd4",
   "metadata": {},
   "source": [
    "Mijn stage folder staat vol met een hoop Notebooks zonder dat de nuance duidelijk is. Dit bestand geeft de stappen van een Computer Vision project en verwijst je naar de bijhorende bestanden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b05df9-870e-4125-82bf-87ddecd56501",
   "metadata": {},
   "source": [
    "Run `!pip install -r requirements.txt` of \n",
    "vul `python -m pip install -r requirements.txt` in een cmd in de folder van de locatie van dit bestand, dit geeft zicht op het download proces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751983a-f2d9-49d8-9d22-14a72ff576c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a665bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, FileLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d09f92-0c44-4121-88cb-78447ab06f55",
   "metadata": {},
   "source": [
    "## Dataset Samenstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50476a23-2af5-4c49-8875-2b13d58ab837",
   "metadata": {},
   "source": [
    "Het bouwen van een Computer Vision model begint bijna altijd bij het verzamelen van de data. Wanneer de dataset perfect is is succes van het model zo goed als gegarandeerd. Bestudeer onderstaande notebook voor alle ins en outs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e1ed824-e0b0-432a-a2a8-99dc28d642dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='informatie\\dataset samenstellen.ipynb' target='_blank'>informatie\\dataset samenstellen.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Computer-Vision-Showcase-SUPERP\\informatie\\dataset samenstellen.ipynb"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('informatie\\\\dataset samenstellen.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8e32d-a7c6-436a-a5f4-60ed66ac5cd9",
   "metadata": {},
   "source": [
    "Voor je de dataset samenstelt moet de keuze tussen de verschillende vormen van computer vision al zijn gedaan. Met als keuzes: Classification, Detection en Segmentation. Als het niet duidelijk is welk type model je wilt maken ga door naar het kopje 'Model Trainen' -> 'Model keuze'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d1ed4-6530-4df4-a07a-d46ab2046822",
   "metadata": {},
   "source": [
    "## Data Verwerken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eaa4d0-cf9d-4837-8213-750d6fe867a1",
   "metadata": {},
   "source": [
    "Voor dat de data wordt gebruikt om het model te trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e64081c-7f00-45fe-bbc7-654a9e51623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='informatie\\Data Verwerken.ipynb' target='_blank'>informatie\\Data Verwerken.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Computer-Vision-Showcase-SUPERP\\informatie\\Data Verwerken.ipynb"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('informatie\\\\Data Verwerken.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f343ed-ffab-447f-b575-acba4e922a25",
   "metadata": {},
   "source": [
    "## Model Trainen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805251b-7f5d-40d8-88ed-572d9ce27166",
   "metadata": {},
   "source": [
    "### Model Keuze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02fbd1-8682-4567-b928-1405294fe1f4",
   "metadata": {},
   "source": [
    "Om te bepalen welk type model je gaat maken kijk je naar het doel van het project.\n",
    "\n",
    "   - Moet het model objecten in een afbeelding classificeren? *(De gehele afbeelding als een klasse zien)* **Classification**\n",
    "   - Moet het model objecten lokaliseren en identificeren? *(Klasse in de afbeelding vinden en de locatie daarvan)* **Detection**\n",
    "   - Moet het model elke pixel van een afbeelding classificeren in een bepaald segment? *(Is elke pixel in de afbeelding van belang?)* **Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607e501-fa19-45d1-ae03-ec85dd8dc4ce",
   "metadata": {},
   "source": [
    "Wanneer je een nieuw model wilt opbouwen is het goed om eerst naar soort gelijke projecten te kijken om te zien wat werkt. In het algemeen is de beste keuze om gebruik te maken van een pre-trained model die al kennis heeft over je klasse. Neem als voorbeeld ResNet50, een model wat getraind is op 1000 klasse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ef1f07f-e4ca-4f68-ae6e-c26509461522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='..\\Data\\imagenet-classes.txt' target='_blank'>..\\Data\\imagenet-classes.txt</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Data\\imagenet-classes.txt"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet50 classes\n",
    "FileLink('..\\\\Data\\\\imagenet-classes.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91038cf5-517d-44e5-8032-b3de61dcc4b2",
   "metadata": {},
   "source": [
    "Door zo'n voorgetraind model te nemen weet je dat de architectuur correct is voor soortgelijke opdrachten. Verder bezitten de weights al informatie over je mogelijke targets/doel klasse, dit kan het train proces een stuk sneller maken doordat het niet vanaf 0 begint. (Dit principe wordt ook transfer learning genoemd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb151b5-f9d0-48f7-afa3-be693d4ee6f8",
   "metadata": {},
   "source": [
    "Bekijk onderstaande notebook voor vragen die kunnen helpen met het maken van een keuze tussen welke pre-trained model / structuur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6224d2-9ffe-4317-a55c-41b5c9386348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Overig\\model keuze.ipynb' target='_blank'>Overig\\model keuze.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Notebooks\\Overig\\model keuze.ipynb"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('Overig\\\\model keuze.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a8d1d-0f09-4207-9074-14bbf70afbb5",
   "metadata": {},
   "source": [
    "### Hyperparameters \n",
    "Loss, optimizers en evaluatiemetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58345af3-c1f3-49c3-b4be-2ad1a7f082cd",
   "metadata": {},
   "source": [
    "Op het moment dat je de model keuze hebt gemaakt is het tijd voor de hyperparameters, dit zijn de verschillende functies / methodes die het model achter de schermen laten runnen. Dit is vaak ook het deel waar verschillende opties worden geprobeerd voor het behalen van een beter of sneller resultaat. Weet wel dat op het moment dat de data en het resultaat niet goed is dat het aanpassen van de hyperparameters dit niet toch succesvol kan maken. Zie dit meer als het bijsleutelen van het model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b2e0c-fff3-42a6-8736-87268818a0c9",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18632e3-f93b-4e6e-a9c2-8e2998c507aa",
   "metadata": {},
   "source": [
    "De criterion of vaker genoemde loss function houdt de afwijking van het model bij, specifieker de afstand tussen het voorspelde antwoord en het correcte antwoord op basis van een formule. Modellen en doeleindes verschillen zo dus ook de loss functions. Het is mogelijk onderzoek te doen naar welke loss function optimaal is voor huidige doeleindes maar raad dit af. Dit process is ook goed te doen door middel van het resultaat testen, ChatGPT vragen of na het bepalen van een optimizer een goed bijpassende loss function te kiezen.\n",
    "\n",
    "[Diepere uitleg werking loss-function](https://www.datacamp.com/tutorial/loss-function-in-machine-learning)  -  [Veel voorkomende loss-functions](https://builtin.com/machine-learning/common-loss-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9517f8-e5cb-4266-81c4-83a49e6e80d2",
   "metadata": {},
   "source": [
    "##### Standaard Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637dc1e1-05f9-4cb5-b7d4-a78a704a8ce9",
   "metadata": {},
   "source": [
    "1. **Image Classification:**\n",
    "   - **Categorical Cross-Entropy:** Wordt vaak gebruikt bij meerklasse-classificatieproblemen.\n",
    "   - **Binary Cross-Entropy:** Wordt gebruikt voor tweetalige classificatieproblemen.\n",
    "\n",
    "[Cross-Entropy](https://365datascience.com/tutorials/machine-learning-tutorials/cross-entropy-loss/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf54e3-9504-4c8d-af68-b4f6f5f250d0",
   "metadata": {},
   "source": [
    "2. **Object Detectie:**\n",
    "   - **Focal Loss:** Helpt bij het omgaan met klassenonevenwicht door moeilijkere voorbeelden te benadrukken.\n",
    "   - **Intersection over Union Loss:** Wordt soms gebruikt om de nauwkeurigheid van boksvoorstellen te verbeteren.\n",
    "   - **Smooth L1 Loss:** Wordt gebruikt in modellen zoals Faster R-CNN voor co√∂rdinatieregressie.\n",
    "   - **YOLO Loss en SSD Loss:** Specifieke combinaties van classificatie- en regressieverliezen die worden gebruikt in respectievelijk YOLO- en SSD-modellen.\n",
    "\n",
    "[YOLO Loss Explained](https://stats.stackexchange.com/questions/287486/yolo-loss-function-explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e3191-f9a5-4ba7-9f6c-5202aab943c8",
   "metadata": {},
   "source": [
    "3. **Segmentatie:**\n",
    "   - **Soft Dice Loss:** Populair in medische beeldsegmentatie, met name bij onevenwichtige klassen.\n",
    "   - **Jaccard Loss (Intersection over Union Loss):** Wordt soms gebruikt voor pixelwijzematchingscores.\n",
    "   - **Cross-Entropy Loss:** Wordt vaak gebruikt in semantische segmentatietaken voor pixelwijze classificatie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b13b8-a5ba-4fe4-9c3d-bcbc5a20a42c",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc152c8-750b-41fa-89e7-271e790aacd8",
   "metadata": {},
   "source": [
    "In Machine Learning projecten spelen optimizers in het algemeen een cruciale rol bij het trainen van modellen. De keuze voor een specifieke optimizer kan afhangen van verschillende factoren, inclusief de aard van de dataset, het model, en de gewenste balans tussen snelheid en nauwkeurigheid. Bekijk onderstaande video's voor een beter begrip over de werking van een optimizer.\n",
    "\n",
    "[3Blue 1Brown: Gradient Descent how Neural Networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w) - [Gradient Descent - 3 minutes](https://www.youtube.com/watch?v=qg4PchTECck)\n",
    "\n",
    "Hier zijn enkele standaardopties voor optimizers en overwegingen waarom je welke zou gebruiken:\n",
    "\n",
    "**Adam (Adaptive Moment Estimation):**\n",
    "\n",
    "[Adam Explained](https://builtin.com/machine-learning/adam-optimization)\n",
    "   - **Standaard Opties:** Goed gedefinieerde standaard parameters (\\(\\beta_1 = 0.9\\), \\(\\beta_2 = 0.999\\)), die meestal goede prestaties leveren zonder veel tuning.\n",
    "   - **Overwegingen:** Adam is vaak de eerste keuze als je snel resultaten wilt krijgen zonder veel tufines. Het combineert de voordelen van twee andere veelgebruikte methodes: AdaGrad en RMSProp.\n",
    "\n",
    "**Stochastic Gradient Descent (SGD):**\n",
    "\n",
    "[Stochastic Gradient Descent Explained](https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31)\n",
    "   - **Standaard Opties:** Vaak gebruikt met momentum, wat helpt om oscillaties (het heen en weer bewegen tussen twee uiterste waardes - vaak tezien in de loss) tijdens het trainen te verminderen en een snellere convergentie (het punt waarop de voorspellingen van het model niet meer verbeteren, of de loss constant wordt) te bereiken.\n",
    "   - **Overwegingen:** SGD met momentum is geschikt voor grote datasets en situaties waar je de convergentie fijn wilt afstemmen. Het vereist handmatige tuning van de leersnelheid, wat zowel een nadeel als een voordeel kan zijn.\n",
    "\n",
    "**AdaGrad:**\n",
    "   - **Standaard Opties:** Past de leersnelheid aan voor elke parameter op basis van de som van de vierkanten van alle voorgaande gradients.\n",
    "   - **Overwegingen:** Goed voor zeldzame en sprankelende kenmerken, maar kan problematisch worden als de leersnelheid te veel daalt.\n",
    "\n",
    "**RMSProp:**\n",
    "\n",
    "[RMSProp Explained](https://www.datacamp.com/tutorial/rmsprop-optimizer-tutorial)\n",
    "   - **Standaard Opties:** Houdt een bewegend gemiddelde van de vierkante gradients bij, en deelt door de wortel van deze gemiddelde waarde.\n",
    "   - **Overwegingen:** Ontwikkeld om de valkuilen van AdaGrad op te lossen, en werkt goed voor niet-stationaire doelen, wat vaak het geval is in real-world deep learning.\n",
    "\n",
    "**AdamW:**\n",
    "   - **Standaard Opties:** Een variant van Adam met decoupled weight decay. Dit voorkomt problemen die voortkomen uit de standaard L2 regularisatie in Adam.\n",
    "   - **Overwegingen:** Helpt bij de algemene generalisatie en convergentie en is vaak beter bij het trainen van transformer-gebaseerde modellen.\n",
    "\n",
    "**Nesterov Accelerated Gradient (NAG):**\n",
    "   - **Standaard Opties:** Een variatie van momentum-gebaseerde methodes die verder moet helpen om sneller te convergeren.\n",
    "   - **Overwegingen:** Het kan nuttig zijn voor zeer diepe netwerken vanwege hun abiliteit om zijn horizon van leersnelheden voor elke parameter aan te passen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91c8f6-b3dc-4e0a-a3bb-68557ccf32d4",
   "metadata": {},
   "source": [
    "##### Overwegingen bij het kiezen van een optimizer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a54da9-f76c-445f-8ebe-93e8e5122dcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- **Niet-lineaire datasets:** Opties zoals Adam helpen met het leren van complexe patronen door dynamische aanpassingen van de leersnelheid.\n",
    "- **Rekenkosten:** Simpele optimizers zoals SGD kunnen effici√´nter zijn in termen van geheugen en snelheid op heel grote datasets.\n",
    "- **Tuning-behoeften:** Sommige optimizers zoals Adam vereisen minder hyperparameter tuning, terwijl optimizers zoals SGD aanzienlijke moeite kunnen vereisen om ze goed te tunen.\n",
    "- **Generalisatie:** Weight decay en optimizerkeuzes zoals AdamW kunnen helpen om overfitting te beperken en beter te generaliseren naar testdata.\n",
    "\n",
    "Bij het kiezen van een optimizer, moet je ook overwegen wat historisch goed heeft gewerkt voor vergelijkbare taken en modellen binnen jouw specifieke domein. Het kan nuttig zijn om met verschillende optimizers te experimenteren om te zien welke het beste presteert in jouw specifieke situatie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd3e74-6062-447e-8680-4294d600ea6b",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e8eae-e727-4e37-b921-a44fd45d5300",
   "metadata": {},
   "source": [
    "Tijdens het trainen zijn er verschillende evaluatie metrics om in de gaten te houden. Bij image detection komen er nog een paar bij, deze worden in het `Image Detection` deel behandeld.\n",
    "Bij image classification zijn verschillende metrics die je kunt gebruiken om de prestaties van je model te evalueren. Hier zijn de meest voorkomende:\n",
    "\n",
    "1. **Accuracy**: Dit meet het percentage correcte voorspellingen over alle voorbeelden. Hoewel het nuttig is, kan het misleidend zijn in geval van een scheve klassenverdeling.\n",
    "\n",
    "2. **Precision**: Dit is het percentage daadwerkelijke positieve voorspellingen uit alle positieve voorspellingen. Het is vooral nuttig als de kosten van vals-positieven hoog zijn.\n",
    "\n",
    "3. **Recall (of Sensitivity)**: Dit is het percentage correcte positieve voorspellingen uit alle daadwerkelijke positieve gevallen. Het is cruciaal wanneer de kosten van gemiste positieve voorbeelden hoog zijn.\n",
    "\n",
    "4. **F1-score**: Dit is het harmonisch gemiddelde van precision en recall. Het is nuttig wanneer je een balans wilt vinden tussen precision en recall, vooral bij een ongelijke klassenverdeling.\n",
    "\n",
    "5. **Confusion Matrix**: Dit is een tabel die de prestaties van een classificatiemodel laat zien, met de werkelijke klassen tegenover de voorspelde klassen. Het geeft inzicht in correct geclassificeerde en verkeerd geclassificeerde voorspellingen.\n",
    "\n",
    "Deze metrics helpen je verschillende aspecten van je modelprestaties te begrijpen, en de keuze van welke te gebruiken hangt vaak af van de specificiteiten en eisen van je project. Zo is voor een toezicht systeem `precision` van hoger belang voor het voorkomen van false positives. Bij het herkennen van tumors is `recall` belangrijker aangezien false negatives veel schadelijker zijn dan false positives. Bepaal opbasis van wat voor jou model het handigst op welke metrics je het meest gaat letten.  In het geval je het zo simpel mogelijk voor jezelf wilt maken let dan op de `F1-score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f654648-fc3a-4c51-a697-3a8b1ddedda2",
   "metadata": {},
   "source": [
    "#### Trainingsprocedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7b938-c77f-49eb-89c1-d4d53bd89a02",
   "metadata": {},
   "source": [
    "Tijdens het train proces krijg je altijd te maken met batch size en epochs, dit zijn de hoeveelheid afbeeldingen voor het model de weights aanpast en het totaal aantal keer dat het model door de hele trainings data heen gaat. [Verdere uitleg](https://www.sabrepc.com/blog/Deep-Learning-and-AI/Epochs-Batch-Size-Iterations)\n",
    "\n",
    "Om niet zelf het aantal epochs te hoeven bepalen en zo mogelijk het proces te vroeg of laat te stoppen kan je gebruik maken van [early stopping](https://cyborgcodes.medium.com/what-is-early-stopping-in-deep-learning-eeb1e710a3cf) en/of [learning rate scheduler](https://neptune.ai/blog/how-to-choose-a-learning-rate-scheduler)\n",
    "\n",
    "__Kort om__:\n",
    "- __Batch size en epochs__: Kies de juiste batchgrootte die past bij de hoeveelheid beschikbare GPU/CPU-kracht, dit is standaard 32. Dan trainen we met voldoende epochs om een goede generalisatie te bereiken.\n",
    "- __Early stopping__: Dit is het bijhouden van de loss op de validatie set, als deze een aantal epochs niet verbeterd. We gebruiken early stopping om overfitting te voorkomen. \n",
    "- __Learning rate scheduling__: Gebruik een learning rate scheduler (bijv. reduce on plateau) om de learning rate automatisch aan te passen wanneer de prestaties stagneren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcd335-5d40-4e63-92dd-f54998c80724",
   "metadata": {},
   "source": [
    "## Evaluatie en Implementatie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37be93a-050e-4144-be0c-76a52ddb4618",
   "metadata": {},
   "source": [
    "Nadat het trainen van het model is voltooid is het tijd de resultaten te evalueren. Het balanceren van de complexiteit van een model is essentieel om een goed generaliserend model te ontwikkelen dat even goed presteert op zowel trainings- als testdata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b4937-052d-43e7-8802-84da0d102aff",
   "metadata": {},
   "source": [
    "#### Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f2a943-178b-44a7-8441-894c574f77cf",
   "metadata": {},
   "source": [
    "**Definitie:** Underfitting treedt op wanneer een model te simpel is om de onderliggende patronen in de trainingsdata vast te leggen. Het model presteert slecht op zowel de trainingsdata als de nieuwe, ongeziene data.\n",
    "  \n",
    "**Oorzaken:**\n",
    "  - Een te eenvoudig model kiezen (bijvoorbeeld een lineair model voor een niet-lineaire dataset).\n",
    "  - Onvoldoende trainingsdata of te veel noise in de data.\n",
    "  - Te sterke regularisatie die de complexiteit van het model vermindert.\n",
    "\n",
    "**Gevolgen:** \n",
    "\n",
    "Het model heeft een hoge bias maar een lage variantie, wat resulteert in slechte voorspellingen en generalisering.\n",
    "\n",
    "**Oplossing:**\n",
    "  - Gebruik een complexer model dat rijkere patronen kan vasthouden.\n",
    "  - Gebruik meer relevante features.\n",
    "  - Train langer of met een andere optimizer/hogere leersnelheid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a7271-3004-4325-99b9-f5cbd5360a5c",
   "metadata": {},
   "source": [
    "#### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb79c6d-7962-42c6-ab5c-9f112269c69a",
   "metadata": {},
   "source": [
    "**Definitie:** Overfitting treedt op wanneer een model te complex is en niet alleen de onderliggende patronen in de trainingsdata leert, maar ook de ruis en specifieke details ervan. Hierdoor presteert het uitstekend op de trainingsdata maar slecht op nieuwe, ongeziene data.\n",
    "  \n",
    "**Oorzaken:**\n",
    "  - Een te complex model kiezen (zoals een diep neuraal netwerk zonder voldoende data).\n",
    "  - Te weinig trainingsdata in verhouding tot de complexiteit van het model.\n",
    "  - Gebrek aan regularisatie.\n",
    "\n",
    "**Gevolgen:** \n",
    "\n",
    "Het model heeft een lage bias maar een hoge variantie, wat resulteert in slechte generalisatie naar nieuwe data.\n",
    "\n",
    "**Oplossing:**\n",
    "  - Voeg [regularisatie](https://www.pinecone.io/learn/regularization-in-neural-networks/) toe (zoals [L1 of L2 regularisatie](https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/)).\n",
    "  - Gebruik technieken zoals dropout in neurale netwerken. [Dropout Basics](https://www.dremio.com/wiki/dropout-in-neural-networks/#:~:text=Dropout%20in%20Neural%20Networks%20operates,to%20generalize%20to%20new%20data.) - [Dropout Advanced](https://towardsdatascience.com/dropout-in-neural-networks-47a162d621d9)\n",
    "  - Verzamel meer data of verrijk de dataset door data augmentatie.\n",
    "  - Eenvoudiger model gebruiken dat beter bij de dataset past."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea6bde9-1004-49ba-85ab-196e502cb8c7",
   "metadata": {},
   "source": [
    "### Implementatie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95c23b-3f55-4662-8bfa-0592191cf159",
   "metadata": {},
   "source": [
    "#### Mendix Implementatie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9f9d2-3a51-4e52-a091-d0eb691002a0",
   "metadata": {},
   "source": [
    "Aangezien MxBlue zich richt op (je had het vast niet geraden) Mendix gaan we de implementatie ook alleen uitwerken voor in Mendix.\n",
    "Er zijn andere mogelijkheden, echter is vaak het eindpunt in python of een .pt /.pth bestand.\n",
    "\n",
    "In het geval je met `Pytorch` werkt (waar ik wel vanuit ga) is het opslaan van je model vrij simpel\n",
    "\n",
    "``` Python\n",
    "torch.save(model.state_dict(), 'name_model.pth')\n",
    "```\n",
    "\n",
    "Dit .pth bestand zijn alle weights en biases voor elke layer. En deze kan op zelfde wijze worden gebruikt als de andere pre-trained models. *(Je zet de gewenste model structuur op laad het bestand in)*\n",
    "\n",
    "Vanaf dit punt kan je het __model omzetten__ voor het gebruik in mendix. Onderstaande notebook gaat hier over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00ab0226-cfb0-4143-a6fb-45b6188dafd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Model to mendix\\torch_to_onnx.ipynb' target='_blank'>Model to mendix\\torch_to_onnx.ipynb</a><br>"
      ],
      "text/plain": [
       "E:\\Studie\\Stage\\Notebooks\\Model to mendix\\torch_to_onnx.ipynb"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FileLink('Model to mendix\\\\torch_to_onnx.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
